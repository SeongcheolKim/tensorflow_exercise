{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNnubqzysfNRrC6o+QImnfa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongcheolKim/word2vec/blob/main/coco.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YrglC-cUvjzg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "Hf3rrbBsL08W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 로드\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "Jw4fIgT9GYFu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 크기 변경 및 정규화(32, 32)->(224, 224)\n",
        "#배치 크기 설정\n",
        "batch_size = 32\n",
        "\n",
        "# 레이블 원-핫 인코딩\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "#데이터셋을 만들고 즉시 리사이징하지 않음 (메모리 절약)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "#배치 단위로 변환 (메모리 사용 최적화)\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (224, 224))  # 실시간 리사이징 (RAM 사용 감소)\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n",
        "\n",
        "#`map`을 사용해 데이터 변환 (메모리 최적화)\n",
        "train_dataset = train_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "#배치 단위로 변환 (num_parallel_calls 최적화)\n",
        "train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "egrw5tAEG8bS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "KHX_e662xLfS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fine-tuning 용 FC 추가\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation = 'relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation = 'softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "tHy0qiQHHZxI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer = keras.optimizers.RMSprop(learning_rate=1e-05),\n",
        "    loss = \"categorical_crossentropy\",\n",
        "    metrics = [\"accuracy\"]\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath = \"model_feature.keras\",\n",
        "        save_best_only = True,\n",
        "        monitor = \"val_loss\"\n",
        "    )\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs = 10,\n",
        "    validation_data = test_dataset,\n",
        "    callbacks = callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sznQXK4Hz9k",
        "outputId": "891dd048-7170-4506-eb80-dbe962a4ec3d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 103ms/step - accuracy: 0.0993 - loss: 2.5796 - val_accuracy: 0.1351 - val_loss: 2.2969\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 96ms/step - accuracy: 0.1069 - loss: 2.3306 - val_accuracy: 0.1797 - val_loss: 2.2913\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 96ms/step - accuracy: 0.1185 - loss: 2.2962 - val_accuracy: 0.2011 - val_loss: 2.2868\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 96ms/step - accuracy: 0.1421 - loss: 2.2867 - val_accuracy: 0.2004 - val_loss: 2.2820\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 97ms/step - accuracy: 0.1542 - loss: 2.2827 - val_accuracy: 0.2047 - val_loss: 2.2778\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 97ms/step - accuracy: 0.1617 - loss: 2.2776 - val_accuracy: 0.2337 - val_loss: 2.2734\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 96ms/step - accuracy: 0.1641 - loss: 2.2736 - val_accuracy: 0.2082 - val_loss: 2.2694\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 96ms/step - accuracy: 0.1683 - loss: 2.2692 - val_accuracy: 0.2124 - val_loss: 2.2646\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 97ms/step - accuracy: 0.1741 - loss: 2.2648 - val_accuracy: 0.2356 - val_loss: 2.2599\n",
            "Epoch 10/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 97ms/step - accuracy: 0.1755 - loss: 2.2612 - val_accuracy: 0.2400 - val_loss: 2.2552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet50의 마지막 몇 개의 레이어를 학습 가능하게 변경\n",
        "for layer in base_model.layers[-50:]:  # 마지막 50개 레이어만 Fine-Tuning\n",
        "    layer.trainable = True\n",
        "\n",
        "# 모델 재컴파일 (낮은 Learning Rate 사용)\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),  # 낮은 LR로 미세 조정\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath = \"model_feature.keras\",\n",
        "        save_best_only = True,\n",
        "        monitor = \"val_loss\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Fine-Tuning 학습\n",
        "history_finetune = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=5,  # 추가 5 Epochs\n",
        "    validation_data=test_dataset,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oERAkCG6eQrg",
        "outputId": "323a10de-6407-471e-8c7d-38adecbae125"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 165ms/step - accuracy: 0.3336 - loss: 1.8388 - val_accuracy: 0.3791 - val_loss: 1.7165\n",
            "Epoch 2/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 155ms/step - accuracy: 0.4883 - loss: 1.4391 - val_accuracy: 0.4007 - val_loss: 2.0210\n",
            "Epoch 3/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 155ms/step - accuracy: 0.5301 - loss: 1.3353 - val_accuracy: 0.3508 - val_loss: 2.1804\n",
            "Epoch 4/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 155ms/step - accuracy: 0.5508 - loss: 1.2798 - val_accuracy: 0.4154 - val_loss: 1.7217\n",
            "Epoch 5/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 154ms/step - accuracy: 0.5672 - loss: 1.2371 - val_accuracy: 0.3839 - val_loss: 1.9277\n"
          ]
        }
      ]
    }
  ]
}